# -*- coding: utf-8 -*-
"""pythonwebscraptask1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jWs8XT7rSz-D9alUSNh4PFTHto21dTfW
"""

import os
import requests
import re
from bs4 import BeautifulSoup
from google.colab import files

def fetch_webpage():
    url = "https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7"  # URL is hardcoded
    response = requests.get(url)
    response.raise_for_status()  # Raise an error if the request was unsuccessful
    soup = BeautifulSoup(response.text, 'html.parser')
    return soup

"""# Function to clean up HTML tags and format text accordingly"""

def clean_html_content(text):
    # Dictionary for replacing HTML tags with proper formatting
    replacements = {"<br>": "\n", "<br/>": "\n", "<li>": "\n"}
    replacements = dict((re.escape(key), value) for key, value in replacements.items())
    pattern = re.compile("|".join(replacements.keys()))
    text = pattern.sub(lambda match: replacements[re.escape(match.group(0))], text)
    cleaned_text = re.sub(r'<.*?>', '', text)  # Remove remaining HTML tags
    return cleaned_text

"""# Extracts all paragraph text"""

def extract_page_content(soup, url):
    content = f'URL: {url}\n\n'
    paragraphs = soup.find_all('p')  # Find all paragraph tags
    for para in paragraphs:
        content += f"{para.text}\n\n"
    return content

"""# Save the extracted text into a file and download it"""

def save_and_download(text, url):
    if not os.path.exists('./scraped_data'):
        os.mkdir('./scraped_data')
    filename = url.split("/")[-1]
    filepath = f'scraped_data/{filename}.txt'


    with open(filepath, 'w', encoding='utf-8') as file:
        file.write(text)

    print(f'Text saved in {filepath}')


    files.download(filepath)

if __name__ == '__main__':
    url = "https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7"
    soup = fetch_webpage()
    if soup:
        page_text = extract_page_content(soup, url)
        save_and_download(page_text, url)  # Save the text and trigger download